{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuDOxDHdOtFW"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAtJ8Jh_z-7t",
        "outputId": "93215dcd-fc17-40da-cac3-69f7083f63d2"
      },
      "outputs": [],
      "source": [
        "# Installing required packages\n",
        "!pip install pyspark\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e34Q4qnfz-y8"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession,SQLContext\n",
        "import os #important without this wont work\n",
        "os.environ['PYSPARK_PYTHON'] = 'D:\\\\Python311\\\\python.exe'\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = 'D:\\\\Python311\\\\python.exe'\n",
        "os.environ['JAVA_HOME'] = 'D:\\\\Java\\\\jdk1.8.0_202\\\\'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDOcBO-rkuPB"
      },
      "source": [
        "# Create Spark Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sqOwMWgOwBGi"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"ML_Classifications_example1\") \\\n",
        "    .getOrCreate()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PygI-deIZT-o"
      },
      "outputs": [],
      "source": [
        "sc = spark.sparkContext\n",
        "sqlContext = SQLContext(sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQRG5yVvOyty"
      },
      "outputs": [],
      "source": [
        "# Upload files (Only in colabs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "FWglhYsLwPL0",
        "outputId": "5bcd259d-fe50-4948-e67d-0bcb4ecbb890"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "\n",
        "# uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac8MHqWOkyvb"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZWAofGUswBGl"
      },
      "outputs": [],
      "source": [
        "file='\\\\Users\\\\kimil\\\\OneDrive\\\\Desktop\\\\MUIC_work\\\\BigData\\\\BigData\\\\SparkML\\\\data\\\\drybeans.csv'\n",
        "df = spark.read.csv(file,header='true',inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeX5KsGXwBGm",
        "outputId": "14a503b6-06a8-4ebc-f71c-72ef2df6e461"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vjXANWwwBGm",
        "outputId": "e937f5f9-57fd-4bad-e37d-6739dd7b2761"
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "3WM1mgbBwBGn",
        "outputId": "99d1a95c-b136-44eb-b5ca-f400a19ffa57"
      },
      "outputs": [],
      "source": [
        "df.describe().toPandas().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf3GVJenwBGn",
        "outputId": "60e5f721-1061-47d3-8cc3-c767eee76f8e"
      },
      "outputs": [],
      "source": [
        "df.select([\"Area\",\"Perimeter\",\"Solidity\",\"roundness\",\"Compactness\",\"Class\"]).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfonE2o8wBGo",
        "outputId": "16173f27-004d-44ca-e403-3a00b5eea9e6"
      },
      "outputs": [],
      "source": [
        "df.groupBy('Class').count().orderBy('count').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5-RpzxWlwBGo"
      },
      "outputs": [],
      "source": [
        "# Convert Class column from string to numerical values\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexer = StringIndexer(inputCol=\"Class\", outputCol=\"label\") #addition to the regression\n",
        "df = indexer.fit(df).transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSmrMMjFwBGp",
        "outputId": "8dd84ed9-c5c0-4046-fc67-347fe95a9ca5"
      },
      "outputs": [],
      "source": [
        "df.groupBy('label').count().orderBy('count').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmX1U1HX2i3n"
      },
      "source": [
        "#  Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElV2ZP113G1R"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import DataFrameNaFunctions\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import Binarizer\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktPd8SpG76hy"
      },
      "outputs": [],
      "source": [
        "featureColumns =df.columns[:-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEm523ct2sab"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(inputCols=featureColumns, outputCol=\"features\")\n",
        "df_assembled = assembler.transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx7TeYw6VT3D",
        "outputId": "fe07916d-c041-457b-a36a-03ddf67504bb"
      },
      "outputs": [],
      "source": [
        "df_assembled.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFmGmVU72tnv"
      },
      "outputs": [],
      "source": [
        "(trainingData, testData) = df_assembled.randomSplit([0.8,0.2], seed = 13234 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaZkw9Pi2uzu",
        "outputId": "576aa9d0-dba7-40c7-b8d7-6595311afe39"
      },
      "outputs": [],
      "source": [
        "trainingData.count(),testData.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNpJj2Ko2wmQ"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier,LogisticRegression\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "model = lr.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIIzZ_kH2yU7"
      },
      "outputs": [],
      "source": [
        "#dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=5,minInstancesPerNode=20, impurity=\"gini\")\n",
        "#pipeline = Pipeline(stages=[dt])\n",
        "#model = pipeline.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqQTRppW2zo8"
      },
      "outputs": [],
      "source": [
        "predictions = model.transform(testData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXp0ksB0TQOY",
        "outputId": "9047b575-dfbd-4363-dd9c-cf7d5f9e0e7c"
      },
      "outputs": [],
      "source": [
        "predictions.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W4Z7VUsEAr8",
        "outputId": "3f489d15-a97b-4032-de79-1a17fb7f25b3"
      },
      "outputs": [],
      "source": [
        "predictions.select(\"features\",\"rawprediction\",\"probability\",\"prediction\", \"label\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBUeH1rD21JU",
        "outputId": "12bf99af-58e5-4196-b804-6f48e6a68bf4"
      },
      "outputs": [],
      "source": [
        "prediction_save=predictions.select(\"features\",\"rawprediction\",\"probability\",\"prediction\", \"label\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb-NXq5BUN2p"
      },
      "outputs": [],
      "source": [
        "predictions.select(\"prediction\", \"label\").write.save(path=\"predictions\",\n",
        "                                                     format=\"com.databricks.spark.csv\",\n",
        "                                                     header='true')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dF8nU3AkVizJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "prediction_save=predictions.select(\"prediction\", \"label\").rdd.map(tuple)\n",
        "prediction_save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQd4thPrPJmx"
      },
      "source": [
        "# Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZvA8ltr8meX"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04ab1wtB8mMq"
      },
      "outputs": [],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lWjaRbd8rm7",
        "outputId": "446081f8-bb0d-4d5a-bd3d-4f66c56d75bb"
      },
      "outputs": [],
      "source": [
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy = %g \" % (accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPPyeqhG8vhX",
        "outputId": "ebf626d9-6b37-4eaf-eb87-d886aa555887"
      },
      "outputs": [],
      "source": [
        "# Evaluate model performance\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy =\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZDtglhmVSHZ",
        "outputId": "5d1d06ca-5bc8-4627-afd8-8e9c7bc788ca"
      },
      "outputs": [],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "recall = evaluator.evaluate(predictions)\n",
        "print(\"Recall =\", recall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaKlvTNrVTwl",
        "outputId": "ce5002bf-f479-483b-a80b-a94f6fc0cf51"
      },
      "outputs": [],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1_score = evaluator.evaluate(predictions)\n",
        "print(\"F1 score = \", f1_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJSZKI908xWD",
        "outputId": "7317c97a-7d2c-4776-c26c-935c427ba4ea"
      },
      "outputs": [],
      "source": [
        "metrics = MulticlassMetrics(prediction_save)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN0KiP658zPI",
        "outputId": "11965115-21cd-4dcd-c4ba-e499e237c3fb"
      },
      "outputs": [],
      "source": [
        "metrics.confusionMatrix().toArray().transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq2kcscmPNqq"
      },
      "source": [
        "\n",
        "# Try with fewer features/ Try with Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IlZHqyYaURR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZd4Wv93aUU5"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession,SQLContext\n",
        "import os #important without this wont work\n",
        "os.environ['PYSPARK_PYTHON'] = 'D:\\\\Python311\\\\python.exe'\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = 'D:\\\\Python311\\\\python.exe'\n",
        "os.environ['JAVA_HOME'] = 'D:\\\\Java\\\\jdk1.8.0_202\\\\'\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"ML_Classifications_example1\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "sqlContext = SQLContext(sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyXrF7Tu4514"
      },
      "outputs": [],
      "source": [
        "sc.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJdRtm1ZaV0v"
      },
      "source": [
        "# Exercise Diabates data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3Hi4zp25UFX"
      },
      "outputs": [],
      "source": [
        "file='\\\\Users\\\\kimil\\\\OneDrive\\\\Desktop\\\\MUIC_work\\\\BigData\\\\BigData\\\\SparkML\\\\data\\\\diabetes.csv'\n",
        "df = spark.read.csv(file,header='true',inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.show(5)\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe().toPandas().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.select([\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\",\"Outcome\"]).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import DataFrameNaFunctions\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import Binarizer\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "featureColumns =df.columns[:-2]\n",
        "assembler = VectorAssembler(inputCols=featureColumns, outputCol=\"features\")\n",
        "df_assembled = assembler.transform(df)\n",
        "df_assembled = df_assembled.withColumnRenamed(\"Outcome\",\"label\")\n",
        "df_assembled.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "df_label_0 = df_assembled.filter(df_assembled['label'] == 0).select('Age').toPandas()\n",
        "df_label_1 = df_assembled.filter(df_assembled['label'] == 1).select('Age').toPandas()\n",
        "df_label_0_insu = df_assembled.filter(df_assembled['label'] == 0).select('Insulin').toPandas()\n",
        "df_label_1_insu = df_assembled.filter(df_assembled['label'] == 1).select('Insulin').toPandas()\n",
        "df_label_0_glu = df_assembled.filter(df_assembled['label'] == 0).select('Glucose').toPandas()\n",
        "df_label_1_glu = df_assembled.filter(df_assembled['label'] == 1).select('Glucose').toPandas()\n",
        "\n",
        "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(12, 18))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(df_label_0, x='Age', bins=10, kde=False, color='blue', label='People without diabetes', ax=axes[0])\n",
        "sns.histplot(df_label_1, x='Age', bins=10, kde=False, color='orange', label='People with diabetes', ax=axes[0])\n",
        "axes[0].set_xlabel('Age')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_title('Distribution of Age by diabetes(Label/Outcome)')\n",
        "axes[0].legend()\n",
        "\n",
        "sns.histplot(df_label_0_insu, x='Insulin', bins=10, kde=False, color='blue', label='People without diabetes', ax=axes[1])\n",
        "sns.histplot(df_label_1_insu, x='Insulin', bins=10, kde=False, color='orange', label='People with diabetes', ax=axes[1])\n",
        "axes[1].set_xlabel('Insulin')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].set_title('Distribution of Insulin by diabetes(Label/Outcome)')\n",
        "axes[1].legend()\n",
        "\n",
        "sns.histplot(df_label_0_glu, x='Glucose', bins=10, kde=False, color='blue', label='People without diabetes', ax=axes[2])\n",
        "sns.histplot(df_label_1_glu, x='Glucose', bins=10, kde=False, color='orange', label='People with diabetes', ax=axes[2])\n",
        "axes[2].set_xlabel('Glucose')\n",
        "axes[2].set_ylabel('Frequency')\n",
        "axes[2].set_title('Distribution of Glucose by diabetes(Label/Outcome)')\n",
        "axes[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(trainingData, testData) = df_assembled.randomSplit([0.8,0.2], seed = 13234 )\n",
        "trainingData.count(),testData.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainingData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'trainingData' and 'testData' are Spark DataFrames\n",
        "# Convert to Pandas DataFrames for plotting (assuming they are small enough)\n",
        "training_pd = trainingData.select('*').toPandas()\n",
        "test_pd = testData.select('*').toPandas()\n",
        "\n",
        "# Example: Plotting feature distribution\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(training_pd['label'], bins=10, kde=False, color='blue', label='Training Data')\n",
        "sns.histplot(test_pd['label'], bins=10, kde=False, color='orange', label='Test Data')\n",
        "plt.xlabel('label')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of label in Training and Test Data')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier,LogisticRegression\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "model = lr.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model.transform(testData)\n",
        "predictions.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions.select(\"features\",\"rawprediction\",\"probability\",\"prediction\", \"label\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy = %g \" % (accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate model performance\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy =\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1_score = evaluator.evaluate(predictions)\n",
        "print(\"F1 score = \", f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions.select(\"prediction\", \"label\").write.save(path=\"diabete_predictions\",\n",
        "                                                     format=\"com.databricks.spark.csv\",\n",
        "                                                     header='true')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction_save=predictions.select(\"prediction\", \"label\").rdd.map(tuple)\n",
        "metrics = MulticlassMetrics(prediction_save)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Convert predictions DataFrame to Pandas DataFrame (if small enough) or use Spark's RDD operations\n",
        "predictions_pd = predictions.select(\"prediction\", \"label\").toPandas()\n",
        "\n",
        "# Calculate custom metrics using scikit-learn\n",
        "report = classification_report(predictions_pd['label'], predictions_pd['prediction'])\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics.confusionMatrix().toArray().transpose() \n",
        "#I somehow cannot do confusionMatrix, it works the first time however after that it unfortunately doesnt work anymore \n",
        "# (Colab works fine only local)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HW Excercise ML PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession,SQLContext\n",
        "import os #important without this wont work\n",
        "os.environ['PYSPARK_PYTHON'] = 'D:\\\\Python311\\\\python.exe'\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = 'D:\\\\Python311\\\\python.exe'\n",
        "os.environ['JAVA_HOME'] = 'D:\\\\Java\\\\jdk1.8.0_202\\\\'\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"ML_Classifications_Pipeline\") \\\n",
        "    .getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sqlContext = SQLContext(sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "rel_file='data/drybeans.csv'\n",
        "file = os.path.join(os.getcwd(), rel_file)\n",
        "df = spark.read.csv(file,header='true',inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import DataFrameNaFunctions\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, StandardScaler\n",
        "from pyspark.ml.classification import LogisticRegression,DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "featureColumns =df.columns[:-2]\n",
        "featureColumns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "indexer = StringIndexer(inputCol=\"Class\", outputCol=\"label\")\n",
        "assembler = VectorAssembler(inputCols=featureColumns, outputCol=\"features\")\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "assembled = assembler.transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = Pipeline(stages=[indexer,assembler, scaler, lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "(traindata, testData) = df.randomSplit([0.8,0.2], seed = 140140 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(lr.fitIntercept, [False, True]) \\\n",
        "    .addGrid(lr.maxIter, [5, 10,20]) \\\n",
        "    .build()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[np.float64(0.10769119711936476),\n",
              " np.float64(0.11004629236083396),\n",
              " np.float64(0.8801365645336956),\n",
              " np.float64(0.861490263888053),\n",
              " np.float64(0.9126263520563774),\n",
              " np.float64(0.9138081614531232)]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=MulticlassClassificationEvaluator(),\n",
        "                          numFolds=4)  # use 3+ folds in practice\n",
        "\n",
        "# Run cross-validation, and choose the best set of parameters.\n",
        "cvModel = crossval.fit(df)\n",
        "cvModel.avgMetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+--------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "| Area|Perimeter|MajorAxisLength|MinorAxisLength|AspectRation|Eccentricity|ConvexArea|EquivDiameter|     Extent|   Solidity|  roundness|Compactness|ShapeFactor1|ShapeFactor2|ShapeFactor3|ShapeFactor4|   Class|label|            features|     scaled_features|       rawPrediction|         probability|prediction|\n",
            "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+--------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|20464|  528.408|     191.249312|    136.3684624| 1.402445321| 0.701123073|     20772|  161.4173908|0.747406866|0.985172347|0.921004226|0.844015537| 0.009345647| 0.002925438| 0.712362227| 0.999049071|DERMASON|  0.0|[20464.0,528.408,...|[0.69785613161188...|[25.8491675299281...|[0.99999995133974...|       0.0|\n",
            "|20548|  524.736|    183.9652515|    142.6723878| 1.289424354| 0.631298586|     20825|  161.7483421|0.759686483|0.986698679|0.937772948| 0.87923312| 0.008952952| 0.003300366|  0.77305088| 0.996790631|DERMASON|  0.0|[20548.0,524.736,...|[0.70072067007237...|[25.1223763884454...|[0.99999841133760...|       0.0|\n",
            "|21348|  530.825|    191.9944944|    141.8595366| 1.353412672| 0.673844773|     21590|    164.86697|0.725974291|0.988791107|0.952060005|0.858706759| 0.008993559| 0.003016413| 0.737377298| 0.997975778|DERMASON|  0.0|[21348.0,530.825,...|[0.72800198874367...|[25.0692841012088...|[0.99999977067131...|       0.0|\n",
            "|21558|  539.466|    197.2521197|    139.4166267| 1.414839279| 0.707419363|     21808|  165.6758827|0.728926458|0.988536317|0.930872445|0.839919403| 0.009149834| 0.002808946| 0.705464604| 0.998119032|DERMASON|  0.0|[21558.0,539.466,...|[0.73516333489489...|[24.7288147344244...|[0.99999985611204...|       0.0|\n",
            "|22069|  561.523|    208.0328728|    135.9878443| 1.529790209|  0.75676727|     22426|  167.6279318|0.683801202|0.984080977|0.879543694|0.805776172| 0.009426475| 0.002451245| 0.649275239| 0.993254903|DERMASON|  0.0|[22069.0,561.523,...|[0.75258927719618...|[23.9886984732557...|[0.99999942317641...|       0.0|\n",
            "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+--------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictionsCV = cvModel.transform(testData)\n",
        "predictionsCV.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1: 0.9214791960308689\n",
            "precisionByLabel: 0.9403409090909091\n",
            "recallByLabel: 0.9118457300275482\n",
            "weightedPrecision: 0.9217719212369953\n",
            "weightedRecall: 0.9213813372520205\n",
            "accuracy: 0.9213813372520205\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "def evaluate(result):\n",
        "    predictionAndLabels = result.select(\"prediction\", \"label\")\n",
        "    metrics = [\"f1\",\"precisionByLabel\",\"recallByLabel\",\"weightedPrecision\",\"weightedRecall\",\"accuracy\"]\n",
        "    for m in metrics:\n",
        "        evaluator = MulticlassClassificationEvaluator(metricName=m)\n",
        "        print(str(m) + \": \" + str(evaluator.evaluate(predictionAndLabels)))\n",
        "evaluate(predictionsCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = pipeline.fit(traindata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+--------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "| Area|Perimeter|MajorAxisLength|MinorAxisLength|AspectRation|Eccentricity|ConvexArea|EquivDiameter|     Extent|   Solidity|  roundness|Compactness|ShapeFactor1|ShapeFactor2|ShapeFactor3|ShapeFactor4|   Class|label|            features|     scaled_features|       rawPrediction|         probability|prediction|\n",
            "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+--------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|20464|  528.408|     191.249312|    136.3684624| 1.402445321| 0.701123073|     20772|  161.4173908|0.747406866|0.985172347|0.921004226|0.844015537| 0.009345647| 0.002925438| 0.712362227| 0.999049071|DERMASON|  0.0|[20464.0,528.408,...|[0.69684596376064...|[25.6498392983551...|[0.99997783460593...|       0.0|\n",
            "|20548|  524.736|    183.9652515|    142.6723878| 1.289424354| 0.631298586|     20825|  161.7483421|0.759686483|0.986698679|0.937772948| 0.87923312| 0.008952952| 0.003300366|  0.77305088| 0.996790631|DERMASON|  0.0|[20548.0,524.736,...|[0.69970635571509...|[23.3186061553631...|[0.99997250055064...|       0.0|\n",
            "|21348|  530.825|    191.9944944|    141.8595366| 1.353412672| 0.673844773|     21590|    164.86697|0.725974291|0.988791107|0.952060005|0.858706759| 0.008993559| 0.003016413| 0.737377298| 0.997975778|DERMASON|  0.0|[21348.0,530.825,...|[0.72694818385273...|[24.2031220893578...|[0.99999456254869...|       0.0|\n",
            "|21558|  539.466|    197.2521197|    139.4166267| 1.414839279| 0.707419363|     21808|  165.6758827|0.728926458|0.988536317|0.930872445|0.839919403| 0.009149834| 0.002808946| 0.705464604| 0.998119032|DERMASON|  0.0|[21558.0,539.466,...|[0.73409916373886...|[24.8692849152643...|[0.99998855275539...|       0.0|\n",
            "|22069|  561.523|    208.0328728|    135.9878443| 1.529790209|  0.75676727|     22426|  167.6279318|0.683801202|0.984080977|0.879543694|0.805776172| 0.009426475| 0.002451245| 0.649275239| 0.993254903|DERMASON|  0.0|[22069.0,561.523,...|[0.75149988146177...|[25.7485031134791...|[0.99974796813809...|       0.0|\n",
            "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+--------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions = model.transform(testData)\n",
        "predictions.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1: 0.9265614804147871\n",
            "precisionByLabel: 0.9367977528089888\n",
            "recallByLabel: 0.918732782369146\n",
            "weightedPrecision: 0.9267282615621796\n",
            "weightedRecall: 0.9265246142542247\n",
            "accuracy: 0.9265246142542248\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "def evaluate(result):\n",
        "    predictionAndLabels = result.select(\"prediction\", \"label\")\n",
        "    metrics = [\"f1\",\"precisionByLabel\",\"recallByLabel\",\"weightedPrecision\",\"weightedRecall\",\"accuracy\"]\n",
        "    for m in metrics:\n",
        "        evaluator = MulticlassClassificationEvaluator(metricName=m)\n",
        "        print(str(m) + \": \" + str(evaluator.evaluate(predictionAndLabels)))\n",
        "\n",
        "evaluate(predictions)\n",
        "# evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "# accuracy = evaluator.evaluate(predictions)\n",
        "# print(\"Accuracy = \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "sc.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
